{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual, Output, Controller\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "import functools\n",
    "from jupyter_ui_poll import ui_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beep signals during training\n",
    "import jupyter_beeper\n",
    "\n",
    "b = jupyter_beeper.Beeper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blgd-v0 - BlindGrasp with Discrete actions-v0\n",
    "#GUT=True - works only locally and not in Google Colab\n",
    "#ResetCount=250, Reset after 250 actions\n",
    "env=gym.make(\"gym_blg:blgd-v0\", GUI=True,ResetCount=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_obs(obs):\n",
    "    #decodes the observation into sensor readings (normalized)\n",
    "    #proximity\n",
    "    # - Proximity sensor array, 22 values, 0 or 1\n",
    "    # - we are using only using the sensors from the tip - 7 on side and 4 at tip of each fingwe\n",
    "    #pos\n",
    "    # - End effector x,y,z position - (stacked with 2 previous positions for temporal info)\n",
    "    #   9 values - normalized between 0 and 1 \n",
    "    #force\n",
    "    # - End Effector x,y,x force - 3 values, normalized between 0-1\n",
    "    #ObjMap\n",
    "    # - The workspace(tray) are is divided into 32x32 cells\n",
    "    # - ObjMap marks those positions/cells where the proximity sensors detected the presence of any object\n",
    "    # - If object present 1, else 0\n",
    "    #VisitMap\n",
    "    # - VisitMap marks the cells (of 32x32 array) visited by end effector as 1.\n",
    "    # - This info is to incentivize the agent to visit unexplored cells\n",
    "    #CurPosMap\n",
    "    # - The cell corresponding to the xy position of end effector is 1 in this 32x32 array\n",
    "    #GelSight1 and GelSight2\n",
    "    # - GelSight Depth data from the gripper, 32x32 each\n",
    "    # - values normalized between 0-1\n",
    "    prox = obs[:17]\n",
    "    pos = obs[17:26]\n",
    "    force = obs[26:29]\n",
    "    ObjMap= obs[29:1053] #1053 = 29 +(32*32)\n",
    "    VisitMap = obs[1053:2077] #2077=1053+(32*32)\n",
    "    CurPosMap =obs[2077:3101] #3101=2077+(32*32)\n",
    "    #GelSight1=obs[3101:4125] #4125=3101+(32*32)\n",
    "    #GelSight2=obs[4125:5149]# 5149=4125+(32*32) \n",
    "    return prox,pos,force,ObjMap,VisitMap,CurPosMap#,GelSight1, GelSight2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humancmd = None\n",
    "ui_done = False\n",
    "#GUI button callback\n",
    "def on_button_clicked(b, rs_=0):\n",
    "    #step\n",
    "    global ui_done\n",
    "    global humancmd\n",
    "    humancmd = rs_\n",
    "    ui_done= True\n",
    "    '''\n",
    "    obs, rew,Done,misc  = env.step(rs_)\n",
    "    #decode observations\n",
    "    #prox,pos,force,ObjMap,VisitMap,CurPosMap,GelSight1, GelSight2 = decode_obs(obs)\n",
    "    #remove gelsight\n",
    "    prox,pos,force,ObjMap,VisitMap,CurPosMap = decode_obs(obs)\n",
    "   \n",
    "    #update maps\n",
    "    #add CurPosMap to ObjMap and VisitMap for more intuitive visualization\n",
    "    map_id1.set_data((ObjMap.reshape(32,32)+(CurPosMap.reshape(32,32)*10.0)))\n",
    "    map_id2.set_data((VisitMap.reshape(32,32)+(CurPosMap.reshape(32,32)*10.0)))\n",
    "    #map_id3.set_data(CurPosMap.reshape(32,32))\n",
    "    #remove gelsight\n",
    "    #map_id4.set_data(GelSight1.reshape(32,32))\n",
    "    #map_id5.set_data(GelSight2.reshape(32,32))\n",
    "    #TODO -  save the state-action-obs-reward for pretraining the agent\n",
    "    rBox.value=rew\n",
    "    pos = np.around(pos,3)\n",
    "    force = np.around(force,3)\n",
    "    tBoxVal = str(pos[0])+\" \"+ str(pos[1])+\" \"+str(pos[2]) +\" F \" + str(force[0]) +\" \"+ str(force[1]) +\" \"+ str(force[2])\n",
    "    #print(rew)\n",
    "    tBox.value=tBoxVal\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset callback from GUI button\n",
    "def resetenv(b):\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the GUI buttons\n",
    "buttonl = widgets.Button(description=\"Left\")\n",
    "buttonr = widgets.Button(description=\"Right\")\n",
    "buttonf = widgets.Button(description=\"Fwd\")\n",
    "buttonb = widgets.Button(description=\"Back\")\n",
    "buttonl.style.button_color = 'lightgreen'\n",
    "buttonr.style.button_color = 'lightgreen'\n",
    "buttonf.style.button_color = 'lightgreen'\n",
    "buttonb.style.button_color = 'lightgreen'\n",
    "\n",
    "buttonfl = widgets.Button(description=\"F Left\")\n",
    "buttonfr = widgets.Button(description=\"F Right\")\n",
    "buttonbl = widgets.Button(description=\"B Left\")\n",
    "buttonbr = widgets.Button(description=\"B Right\")\n",
    "\n",
    "buttonu = widgets.Button(description=\"Up\")\n",
    "buttond = widgets.Button(description=\"Down\")\n",
    "buttonuj = widgets.Button(description=\"Up 10x\")\n",
    "buttondj = widgets.Button(description=\"Down 10x\")\n",
    "buttonu.style.button_color = 'lightblue'\n",
    "buttond.style.button_color = 'lightblue'\n",
    "buttonuj.style.button_color = 'lightblue'\n",
    "buttondj.style.button_color = 'lightblue'\n",
    "\n",
    "\n",
    "buttongro = widgets.Button(description=\"Gripper Open\")\n",
    "buttongrc = widgets.Button(description=\"Gripper Close\")\n",
    "buttongro.style.button_color = 'moccasin'\n",
    "buttongrc.style.button_color = 'moccasin'\n",
    "\n",
    "buttonrst = widgets.Button(description=\"RESET\")\n",
    "buttonrst.style.button_color = 'red'\n",
    "#Define the callback\n",
    "buttonl.on_click(functools.partial(on_button_clicked, rs_=4))\n",
    "buttonr.on_click(functools.partial(on_button_clicked, rs_=5))\n",
    "buttonf.on_click(functools.partial(on_button_clicked, rs_=6))\n",
    "buttonb.on_click(functools.partial(on_button_clicked, rs_=7))\n",
    "\n",
    "buttonfl.on_click(functools.partial(on_button_clicked, rs_=8))\n",
    "buttonfr.on_click(functools.partial(on_button_clicked, rs_=9))\n",
    "buttonbl.on_click(functools.partial(on_button_clicked, rs_=10))\n",
    "buttonbr.on_click(functools.partial(on_button_clicked, rs_=11))\n",
    "\n",
    "buttonu.on_click(functools.partial(on_button_clicked, rs_=0))\n",
    "buttond.on_click(functools.partial(on_button_clicked, rs_=1))\n",
    "buttonuj.on_click(functools.partial(on_button_clicked, rs_=2))\n",
    "buttondj.on_click(functools.partial(on_button_clicked, rs_=3))\n",
    "\n",
    "buttongro.on_click(functools.partial(on_button_clicked, rs_=12))\n",
    "buttongrc.on_click(functools.partial(on_button_clicked, rs_=13))\n",
    "\n",
    "buttonrst.on_click(resetenv)\n",
    "\n",
    "rBox=widgets.FloatText(value=2.0, disabled=True)\n",
    "tBox=widgets.Text(value=\"X-Y-Z Positions - Forces\", disabled=True)\n",
    "\n",
    "#organize the buttons\n",
    "col1=widgets.VBox([buttongro,buttonbl,buttonl,buttonfl])\n",
    "col2=widgets.VBox([buttonb,buttonu,buttond,buttonf])\n",
    "col3=widgets.VBox([buttongrc,buttonbr,buttonr,buttonfr])\n",
    "col4=widgets.VBox([buttonuj,buttondj,buttonrst,rBox])\n",
    "col5=widgets.HBox([tBox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamepad callbacks\n",
    "def on_click2(change):\n",
    "    #print(\"ev\",pad.buttons[0] )\n",
    "    if(pad.buttons[12].value==1.0):\n",
    "        #print(\"F\")\n",
    "        on_button_clicked(None,7)\n",
    "    elif(pad.buttons[13].value==1.0):\n",
    "        #print(\"B\")\n",
    "        on_button_clicked(None,6)\n",
    "    elif(pad.buttons[14].value==1.0):\n",
    "        #print(\"L\")\n",
    "        on_button_clicked(None,4)\n",
    "    elif(pad.buttons[15].value==1.0):\n",
    "        #print(\"R\")\n",
    "        on_button_clicked(None,5)\n",
    "    elif(pad.buttons[4].value==1.0):\n",
    "        #print(\"U\")\n",
    "        on_button_clicked(None,0)\n",
    "    elif(pad.buttons[6].value==1.0):\n",
    "        #print(\"D\")\n",
    "        on_button_clicked(None,1)\n",
    "    elif(pad.buttons[7].value==1.0):\n",
    "        #print(\"DD\")\n",
    "        on_button_clicked(None,3)\n",
    "    elif(pad.buttons[1].value==1.0):\n",
    "        #print(\"O\")\n",
    "        on_button_clicked(None,12)\n",
    "    elif(pad.buttons[2].value==1.0):\n",
    "        #print(\"C\")\n",
    "        on_button_clicked(None,13)\n",
    "    elif(pad.buttons[3].value==1.0):\n",
    "        #print(\"RESET\")\n",
    "        resetenv(None)\n",
    "        #on_button_clicked(None,13)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamepad=True\n",
    "if(gamepad):\n",
    "    pad = Controller()\n",
    "    pad\n",
    "#press any buttons on gamepad, else it may not initialize properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(gamepad):\n",
    "\n",
    "    pad.buttons[12].observe(on_click2, names='value')\n",
    "    pad.buttons[13].observe(on_click2, names='value')\n",
    "    pad.buttons[14].observe(on_click2, names='value')\n",
    "    pad.buttons[15].observe(on_click2, names='value')\n",
    "    pad.buttons[6].observe(on_click2, names='value')\n",
    "    pad.buttons[4].observe(on_click2, names='value')\n",
    "    pad.buttons[7].observe(on_click2, names='value')\n",
    "\n",
    "    pad.buttons[1].observe(on_click2, names='value')\n",
    "    pad.buttons[2].observe(on_click2, names='value')\n",
    "    pad.buttons[3].observe(on_click2, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plots\n",
    "f = plt.figure(figsize=(4,1.5),dpi= 250)\n",
    "\n",
    "i1=f.add_subplot(1,4,1)\n",
    "i1.set_title('ObjMap ')\n",
    "i1.axis('off')\n",
    "map_id1=plt.imshow((np.random.rand(32,32)*10)//2)\n",
    "i2=f.add_subplot(1,4,2)\n",
    "i2.set_title('VisitMap ')\n",
    "i2.axis('off')\n",
    "map_id2=plt.imshow((np.random.rand(32,32)*10)//2)\n",
    "#i3=f.add_subplot(1,5,3)\n",
    "#i3.set_title('CurPosMap ')\n",
    "#i3.axis('off')\n",
    "#map_id3=plt.imshow((np.random.rand(32,32)*10)//2)\n",
    "i4=f.add_subplot(1,4,3)\n",
    "i4.set_title('GelS-1 ')\n",
    "i4.axis('off')\n",
    "map_id4=plt.imshow((np.random.rand(32,32)*10)//2)\n",
    "i5=f.add_subplot(1,4,4)\n",
    "i5.set_title('GelS-2 ')\n",
    "i5.axis('off')\n",
    "map_id5=plt.imshow((np.random.rand(32,32)*10)//2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stable_baselines import PPO2\n",
    "#from stable_baselines.gail import ExpertDataset\n",
    "#TODO - save the action-observation-reward from human demonstration as specified in\n",
    "# https://stable-baselines.readthedocs.io/en/master/guide/pretrain.html#data-structure-of-the-expert-dataset\n",
    "#https://stable-baselines.readthedocs.io/en/master/_modules/stable_baselines/gail/dataset/record_expert.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the env and get initial observation\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 3 #number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "observations = []\n",
    "rewards = []\n",
    "episode_returns = np.zeros((n_episodes,))\n",
    "episode_starts = []\n",
    "ep_rew=[]\n",
    "ep_start = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_idx = 0\n",
    "\n",
    "episode_starts.append(True)\n",
    "reward_sum = 0.0\n",
    "idx = 0\n",
    "rsum=0\n",
    "start_flag  =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/demo_data.npz\"\n",
    "save_count  = 20\n",
    "import os.path\n",
    "data_exists = os.path.exists(save_path)\n",
    "if(data_exists):\n",
    "    prev_data = np.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(obs, rew=0):\n",
    "    prox,pos,force,ObjMap,VisitMap,CurPosMap = decode_obs(obs)\n",
    "    map_id1.set_data((ObjMap.reshape(32,32)+(CurPosMap.reshape(32,32)*10.0)))\n",
    "    map_id2.set_data((VisitMap.reshape(32,32)+(CurPosMap.reshape(32,32)*10.0)))\n",
    "    rBox.value=rew\n",
    "    pos = np.around(pos,3)\n",
    "    force = np.around(force,3)\n",
    "    tBoxVal = str(pos[0])+\" \"+ str(pos[1])+\" \"+str(pos[2]) +\" F \" + str(force[0]) +\" \"+ str(force[1]) +\" \"+ str(force[2])\n",
    "    tBox.value=tBoxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display GUI\n",
    "widgets.HBox([col1,col2,col3,col4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text box to show position and force values\n",
    "widgets.HBox([col5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_exp(npdict):\n",
    "    global actions\n",
    "    global observations \n",
    "    global rewards \n",
    "    #global episode_returns = np.zeros((n_episodes,))\n",
    "    global episode_starts \n",
    "    global ep_start\n",
    "    data_exists = os.path.exists(save_path)\n",
    "\n",
    "    if(data_exists):\n",
    "        prev_data = np.load(save_path)\n",
    "        actions_ = np.append(prev_data['actions'], npdict['actions']).reshape(-1,1)\n",
    "        obs_ = np.append(prev_data['obs'], npdict['obs']).reshape((-1,)+env.observation_space.shape)\n",
    "        rewards_ = np.append(prev_data['rewards'], npdict['rewards'])\n",
    "        episode_returns_ = np.append(prev_data['episode_returns'], npdict['episode_returns'])\n",
    "        episode_starts_ = np.append(prev_data['episode_starts'], npdict['episode_starts'])\n",
    "        #print(\"SAVEcallback\",prev_data['episode_returns'],npdict['episode_returns']  )\n",
    "        \n",
    "        assert len(obs_) == len(actions_)\n",
    "        total_data = {\n",
    "            'actions': actions_,\n",
    "            'obs': obs_,\n",
    "            'rewards': rewards_,\n",
    "            'episode_returns': episode_returns_,\n",
    "            'episode_starts': episode_starts_\n",
    "        }\n",
    "        \n",
    "        for key, val in total_data.items():\n",
    "            print(key, val.shape)\n",
    "        np.savez(save_path, **total_data)  \n",
    "        \n",
    "        #clear old data\n",
    "        actions = []\n",
    "        observations = []\n",
    "        rewards = []\n",
    "        #episode_returns = np.zeros((n_episodes,))\n",
    "        episode_starts = []\n",
    "        ep_start =[]\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(\"savefirst\")\n",
    "        np.savez(save_path, **npdict)\n",
    "        #clear old data\n",
    "        actions = []\n",
    "        observations = []\n",
    "        rewards = []\n",
    "        #episode_returns = np.zeros((n_episodes,))\n",
    "        episode_starts = []\n",
    "        ep_start =[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while ep_idx < n_episodes:\n",
    "    print(\"starting\", ep_idx, idx)\n",
    "    observations.append(obs)\n",
    "    \n",
    "    if(idx==0):\n",
    "        visualize(obs)\n",
    "    else:\n",
    "        visualize(obs,reward)\n",
    "    #get action from human input\n",
    "    #events = get_gamepad() \n",
    "    #while(checkButton()==None):\n",
    "    ui_done = False\n",
    "    #print(\"starting2\", ep_idx, idx)\n",
    "    \n",
    "    with ui_events() as poll:\n",
    "        while ui_done is False:\n",
    "            poll(10)\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "    #humancmd = int(input())\n",
    "    #time.sleep(0.1)\n",
    "    #print(\"starting3\", ep_idx, idx)\n",
    "    action =humancmd\n",
    "    humancmd=None\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    b.beep()\n",
    "    visualize(obs, reward)\n",
    "    \n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    episode_starts.append(done)\n",
    "    reward_sum += reward\n",
    "    idx += 1\n",
    "    ep_start.append(start_flag)\n",
    "    start_flag = False\n",
    "    #print(\"gathering samples\", idx, ep_idx)\n",
    "    #if(idx==0):\n",
    "    #    done = False\n",
    "\n",
    "    if done:\n",
    "        print(\"Done and restart\")\n",
    "        obs = env.reset()\n",
    "        episode_returns[ep_idx] = reward_sum\n",
    "        ep_rew.append(reward_sum)\n",
    "        rsum = reward_sum\n",
    "        reward_sum = 0.0\n",
    "        ep_idx += 1\n",
    "        start_flag = True\n",
    "        \n",
    "        \n",
    "      \n",
    "    #save data periodically\n",
    "    if((idx>2 and (save_count%idx ==0)) or done):\n",
    "        print(\"saving\")\n",
    "        observations_ = np.concatenate(observations).reshape((-1,) + env.observation_space.shape)\n",
    "        actions_ = np.array(actions).reshape((-1, 1))\n",
    "        rewards_ = np.array(rewards)\n",
    "        #episode_starts_ = np.array(episode_starts[:-1])\n",
    "        episode_starts_ = np.array(ep_start)\n",
    "    \n",
    "        assert len(observations_) == len(actions_)\n",
    "        print(\"Save Data \", idx)\n",
    "        if(done):\n",
    "            print(\" saving Done\")\n",
    "            numpy_dict = {\n",
    "                'actions': actions_,\n",
    "                'obs': observations_,\n",
    "                'rewards': rewards_,\n",
    "                'episode_returns': np.array(ep_rew),\n",
    "                'episode_starts': episode_starts_\n",
    "            }# type: Dict[str, np.ndarray]\n",
    "            ep_rew = []\n",
    "        else:\n",
    "            print(\"saving count\")\n",
    "            numpy_dict = {\n",
    "                'actions': actions_,\n",
    "                'obs': observations_,\n",
    "                'rewards': rewards_,\n",
    "                'episode_returns': np.array([]),\n",
    "                'episode_starts': episode_starts_\n",
    "            }\n",
    "        #for key, val in numpy_dict.items():\n",
    "        #     print(key, val.shape)\n",
    "    \n",
    "        if save_path is not None:\n",
    "            save_exp(numpy_dict)\n",
    "            #np.savez(save_path, **numpy_dict)\n",
    "                \n",
    "\n",
    "env.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### '''\n",
    "d = np.load(\"demos.npz\")\n",
    "d2 = np.load(\"demos2.npz\")\n",
    "\n",
    "np.append(d['actions'], d2['actions']).reshape(-1,1)\n",
    "np.append(d['obs'], d2['obs']).reshape((-1,)+env.observation_space.shape)\n",
    "np.append(d['rewards'], d2['rewards'])\n",
    "np.append(d['episode_returns'], d2['episode_returns'])\n",
    "np.append(d['episode_starts'], d2['episode_starts'])\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import PPO2\n",
    "from stable_baselines.gail import ExpertDataset\n",
    "# Using only one expert trajectory\n",
    "# you can specify `traj_limitation=-1` for using the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ExpertDataset(expert_path=save_path,\n",
    "                        traj_limitation=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO2('MlpPolicy',env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pretrain(dataset, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blgenv",
   "language": "python",
   "name": "blgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
